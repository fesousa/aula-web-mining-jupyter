{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from autenticacao import CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import tree, naive_bayes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('rslp')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autenticar no twitter\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets da timeline\n",
    "for status in tweepy.Cursor(api.home_timeline).items(10):\n",
    "    print(status.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pesquisar tweets de um usuario\n",
    "for status in tweepy.Cursor(api.user_timeline, id=\"twitter\").items(10):\n",
    "    # process status here\n",
    "    print(status.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buscar por termos\n",
    "for status in tweepy.Cursor(api.search, q='eleições').items(10):\n",
    "    # process status here\n",
    "    print(status.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitorar tweets\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "\n",
    "    def on_status(self, status):\n",
    "        print(status.text)\n",
    "        # salvar em um arquivo de texto\n",
    "        with open('tweets.txt', 'a', encoding='utf8') as arq:\n",
    "            arq.write(status.text)\n",
    "            arq.write('\\n')\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "       \n",
    "        print('Erro: ' + repr(status_code))\n",
    "        \n",
    "myStreamListener = MyStreamListener(api=tweepy.API(wait_on_rate_limit=True))\n",
    "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener)\n",
    "try:\n",
    "    # track - termos para monitorar\n",
    "    myStream.filter(track=['eleições'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ler base de treinamento\n",
    "treinamento = pd.read_csv('Tweets_Mg.csv')\n",
    "\n",
    "treinamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribuição das classes\n",
    "treinamento.Classificacao.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processamento linguístico\n",
    "# ler arquivo com stopwords e transforma em uma lista\n",
    "stopwords = []\n",
    "with open('stopwords.txt','r', encoding='utf-8') as s:\n",
    "    stopwords = s.read().split('\\n')\n",
    "    \n",
    "def stemmer(doc):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    return ' '.join([stemmer.stem(t) for t in nltk.word_tokenize(doc)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(binary=False,norm='l1', use_idf=True, token_pattern=r'\\b[a-zA-Z]{3,}\\b', stop_words=stopwords, preprocessor=stemmer)\n",
    "vetor = tfidf.fit_transform(treinamento['Text'])\n",
    "categorias = treinamento['Classificacao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar um classificador\n",
    "classif = naive_bayes.GaussianNB()\n",
    "x_train, x_test, y_train, y_test = train_test_split(vetor, categorias, test_size = 0.3) \n",
    "\n",
    "classif.fit(x_train.toarray(), y_train)\n",
    "\n",
    "y_predict = classif.predict(x_test.toarray())\n",
    "acuracia = accuracy_score(y_test, y_predict)\n",
    "acuracia    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classificar novos tweets\n",
    "# ler tweets coletados\n",
    "\n",
    "teste = pd.read_json('tweets_pt.json', lines=True, encoding='utf8')\n",
    "\n",
    "# aplicar tfidf no campo text\n",
    "vetor_test = tfidf.transform(teste['text'])\n",
    "y_test = classif.predict(vetor_test.toarray())\n",
    "\n",
    "# criar dataframe com resultado\n",
    "result = pd.DataFrame({'texto':teste['text'],'sentimento':y_test})\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribuição das classes\n",
    "result.sentimento.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver tweets positivo\n",
    "result[result[\"sentimento\"] == 'Negativo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
